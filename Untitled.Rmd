---
title: "Predicting Critical Temperature of Superconductors: A Linear Regression Analysis"
author: "Your Name"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    theme: united
    code_folding: show
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      fig.width = 10, fig.height = 6)
```

# 1. Introduction

## 1.1 Background

Superconductors are materials that exhibit zero electrical resistance below a critical temperature (T~c~). Predicting this critical temperature is crucial for developing new superconducting materials for applications in:

- Medical imaging (MRI systems)
- Quantum computers
- High-speed trains
- Energy transmission

## 1.2 Objective

This study aims to build a linear regression model to predict the critical temperature (T~c~) using features derived from the superconductor's chemical formula.

## 1.3 Citation

**Required Citation:**  
Hamidieh, Kam. "A data-driven statistical model for predicting the critical temperature of a superconductor." *Computational Materials Science* 154 (2018): 346–354. DOI: 10.1016/j.commatsci.2018.07.052

# 2. Setup and Data Loading

```{r libraries}
# Install packages if needed
# install.packages(c("tidyverse", "corrplot", "car", "MASS", "glmnet", 
#                    "caret", "randomForest", "ggplot2", "gridExtra", 
#                    "GGally", "scales", "knitr", "kableExtra"))

library(tidyverse)      # Data manipulation and visualization
library(corrplot)       # Correlation plots
library(car)            # VIF calculation
library(MASS)           # Box-Cox transformation, stepwise regression
library(glmnet)         # LASSO/Ridge regression
library(caret)          # Machine learning framework
library(randomForest)   # Variable importance
library(ggplot2)        # Visualization
library(gridExtra)      # Multiple plots
library(GGally)         # Pairs plots
library(scales)         # Scaling functions
library(knitr)          # Tables
library(kableExtra)     # Enhanced tables
```

```{r load_data}
# Load the superconductivity dataset from UCI repository
# Method 1: Using ucimlrepo (Python package - not available in R)
# Method 2: Download from UCI website manually
# Method 3: Read from CSV file

# If you have the CSV file:
# data <- read.csv("train.csv")

# For this example, let's use the ucimlrepo approach (requires reticulate)
# Or download from: https://archive.ics.uci.edu/ml/datasets/Superconductivty+Data

# Assuming you have downloaded and saved as 'train.csv'
# Replace with your actual file path
data <- read.csv("train.csv", stringsAsFactors = FALSE)

# Display dataset structure
cat("Dataset Dimensions:", dim(data)[1], "rows x", dim(data)[2], "columns\n")
glimpse(data)
```

# 3. Exploratory Data Analysis (EDA)

## 3.1 Target Variable Analysis

```{r target_analysis}
# Summary statistics of critical temperature
summary(data$critical_temp)

# Create visualization of critical temperature distribution
p1 <- ggplot(data, aes(x = critical_temp)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50, 
                 fill = "steelblue", alpha = 0.7, color = "black") +
  geom_density(color = "red", size = 1.2) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(data$critical_temp), 
                           sd = sd(data$critical_temp)),
                color = "darkgreen", size = 1.2, linetype = "dashed") +
  labs(title = "Distribution of Critical Temperature (Original)",
       subtitle = "Red: Kernel Density | Green: Normal Distribution",
       x = "Critical Temperature (K)",
       y = "Density") +
  theme_minimal()

p2 <- ggplot(data, aes(sample = critical_temp)) +
  stat_qq() +
  stat_qq_line(color = "red", size = 1.2) +
  labs(title = "Q-Q Plot: Critical Temperature (Original)",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles") +
  theme_minimal()

grid.arrange(p1, p2, ncol = 2)
```

```{r skewness}
# Check for skewness
library(e1071)
cat("Skewness of Critical Temperature:", round(skewness(data$critical_temp), 3), "\n")
cat("Kurtosis of Critical Temperature:", round(kurtosis(data$critical_temp), 3), "\n")
```

## 3.2 Box-Cox Transformation

Since the distribution is right-skewed, we apply Box-Cox transformation.

```{r boxcox}
# Box-Cox transformation
bc <- boxcox(critical_temp ~ 1, data = data, plotit = TRUE)
lambda <- bc$x[which.max(bc$y)]
cat("Optimal Lambda:", round(lambda, 3), "\n")

# Apply transformation
data$critical_temp_transformed <- if(lambda != 0) {
  (data$critical_temp^lambda - 1) / lambda
} else {
  log(data$critical_temp)
}

# Visualize transformed distribution
p3 <- ggplot(data, aes(x = critical_temp_transformed)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50, 
                 fill = "coral", alpha = 0.7, color = "black") +
  geom_density(color = "red", size = 1.2) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(data$critical_temp_transformed), 
                           sd = sd(data$critical_temp_transformed)),
                color = "darkgreen", size = 1.2, linetype = "dashed") +
  labs(title = "Distribution of Critical Temperature (Transformed)",
       subtitle = paste0("Box-Cox with λ = ", round(lambda, 3)),
       x = "Transformed Critical Temperature",
       y = "Density") +
  theme_minimal()

p4 <- ggplot(data, aes(sample = critical_temp_transformed)) +
  stat_qq() +
  stat_qq_line(color = "red", size = 1.2) +
  labs(title = "Q-Q Plot: Critical Temperature (Transformed)",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles") +
  theme_minimal()

grid.arrange(p3, p4, ncol = 2)
```

## 3.3 Predictor Variables Analysis

```{r missing_values}
# Check for missing values
missing_summary <- data.frame(
  Variable = names(data),
  Missing_Count = colSums(is.na(data)),
  Missing_Percent = round(colSums(is.na(data)) / nrow(data) * 100, 2)
) %>% 
  filter(Missing_Count > 0) %>%
  arrange(desc(Missing_Count))

if(nrow(missing_summary) > 0) {
  kable(missing_summary, caption = "Missing Values Summary") %>%
    kable_styling(bootstrap_options = c("striped", "hover"))
} else {
  cat("No missing values found!\n")
}
```

```{r predictor_stats}
# Summary statistics for key predictors
predictor_cols <- setdiff(names(data), c("critical_temp", "critical_temp_transformed"))

# Select a few key variables for detailed analysis
key_vars <- c("number_of_elements", "mean_atomic_mass", "wtd_mean_atomic_mass",
              "mean_fie", "wtd_mean_fie", "mean_atomic_radius", 
              "wtd_mean_atomic_radius", "mean_Density", "wtd_mean_Density")

# Check which variables exist in the dataset
key_vars_exist <- key_vars[key_vars %in% names(data)]

if(length(key_vars_exist) > 0) {
  summary_stats <- data %>%
    select(all_of(key_vars_exist)) %>%
    summary()
  print(summary_stats)
}
```

## 3.4 Correlation Analysis

```{r correlation_matrix, fig.width=14, fig.height=12}
# Calculate correlation matrix (excluding target variable)
predictor_data <- data %>% select(-critical_temp, -critical_temp_transformed)
cor_matrix <- cor(predictor_data, use = "complete.obs")

# Visualize correlation matrix
corrplot(cor_matrix, method = "color", type = "upper", 
         tl.col = "black", tl.cex = 0.6, tl.srt = 45,
         col = colorRampPalette(c("blue", "white", "red"))(200),
         title = "Correlation Matrix of Predictor Variables",
         mar = c(0,0,2,0))
```

```{r high_correlation}
# Find highly correlated pairs (|correlation| > 0.9)
high_cor <- which(abs(cor_matrix) > 0.9 & cor_matrix != 1, arr.ind = TRUE)
high_cor_df <- data.frame(
  Var1 = rownames(cor_matrix)[high_cor[, 1]],
  Var2 = colnames(cor_matrix)[high_cor[, 2]],
  Correlation = cor_matrix[high_cor]
) %>%
  filter(as.numeric(as.factor(Var1)) < as.numeric(as.factor(Var2))) %>%
  arrange(desc(abs(Correlation)))

cat("Number of highly correlated pairs (|r| > 0.9):", nrow(high_cor_df), "\n\n")

if(nrow(high_cor_df) > 0) {
  kable(head(high_cor_df, 20), digits = 3,
        caption = "Top 20 Highly Correlated Variable Pairs") %>%
    kable_styling(bootstrap_options = c("striped", "hover"))
}
```

## 3.5 Relationship with Target Variable

```{r target_correlation}
# Correlation with critical temperature
cor_with_target <- cor(predictor_data, data$critical_temp_transformed, 
                       use = "complete.obs")
cor_df <- data.frame(
  Variable = rownames(cor_with_target),
  Correlation = cor_with_target[,1]
) %>%
  arrange(desc(abs(Correlation)))

# Top positive correlations
cat("Top 10 Positively Correlated Features:\n")
print(head(cor_df, 10))

cat("\nTop 10 Negatively Correlated Features:\n")
print(tail(cor_df, 10))

# Visualize
ggplot(cor_df, aes(x = reorder(Variable, Correlation), y = Correlation)) +
  geom_bar(stat = "identity", aes(fill = Correlation > 0)) +
  coord_flip() +
  scale_fill_manual(values = c("coral", "steelblue")) +
  labs(title = "Correlation of Predictors with Critical Temperature",
       x = "Variable", y = "Correlation Coefficient") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 6),
        legend.position = "none")
```

# 4. Feature Selection Methods

## 4.1 Method 1: Correlation-Based Selection

Remove one variable from each highly correlated pair.

```{r correlation_selection}
# Function to remove highly correlated variables
remove_high_cor <- function(data, threshold = 0.9) {
  cor_matrix <- cor(data, use = "complete.obs")
  high_cor <- findCorrelation(cor_matrix, cutoff = threshold)
  
  if(length(high_cor) > 0) {
    removed_vars <- colnames(data)[high_cor]
    data_reduced <- data[, -high_cor]
    cat("Removed", length(removed_vars), "highly correlated variables\n")
    cat("Variables removed:", paste(head(removed_vars, 10), collapse = ", "), "...\n")
    return(list(data = data_reduced, removed = removed_vars))
  } else {
    cat("No highly correlated variables found above threshold\n")
    return(list(data = data, removed = character(0)))
  }
}

# Apply correlation-based selection
cor_result <- remove_high_cor(predictor_data, threshold = 0.9)
data_cor_selected <- cor_result$data
cat("\nReduced to", ncol(data_cor_selected), "predictors\n")
```

## 4.2 Method 2: Variance Inflation Factor (VIF)

Remove variables with high multicollinearity (VIF > 10).

```{r vif_selection}
# Function to calculate and remove high VIF variables iteratively
remove_high_vif <- function(data, target, threshold = 10) {
  vif_data <- cbind(data, target = target)
  removed_vars <- character(0)
  
  repeat {
    if(ncol(vif_data) <= 2) break  # Stop if only target left
    
    formula <- as.formula(paste("target ~", 
                                paste(setdiff(names(vif_data), "target"), 
                                      collapse = " + ")))
    model <- lm(formula, data = vif_data)
    
    vif_values <- vif(model)
    max_vif <- max(vif_values)
    
    if(max_vif > threshold) {
      remove_var <- names(which.max(vif_values))
      removed_vars <- c(removed_vars, remove_var)
      vif_data <- vif_data[, !names(vif_data) %in% remove_var]
      cat("Removed:", remove_var, "with VIF =", round(max_vif, 2), "\n")
    } else {
      break
    }
  }
  
  data_reduced <- vif_data[, !names(vif_data) %in% "target"]
  cat("\nTotal variables removed:", length(removed_vars), "\n")
  cat("Reduced to", ncol(data_reduced), "predictors\n")
  
  return(list(data = data_reduced, removed = removed_vars))
}

# Apply VIF-based selection (this may take a while with many variables)
# For demonstration, we'll use the correlation-reduced dataset
# vif_result <- remove_high_vif(data_cor_selected, data$critical_temp_transformed)
# data_vif_selected <- vif_result$data

# For speed, we'll skip VIF in this demo or use a subset
cat("VIF selection can be computationally intensive with 81+ variables.\n")
cat("Consider using correlation-based or LASSO selection first.\n")
```

## 4.3 Method 3: LASSO Regression

LASSO automatically performs feature selection by shrinking coefficients to zero.

```{r lasso_selection}
# Prepare data for LASSO
X <- as.matrix(predictor_data)
y <- data$critical_temp_transformed

# Split data for LASSO
set.seed(123)
train_idx <- sample(1:nrow(X), 0.7 * nrow(X))
X_train <- X[train_idx, ]
y_train <- y[train_idx]
X_test <- X[-train_idx, ]
y_test <- y[-train_idx]

# Fit LASSO with cross-validation
cv_lasso <- cv.glmnet(X_train, y_train, alpha = 1, nfolds = 10)

# Plot CV results
plot(cv_lasso, main = "LASSO: Cross-Validation MSE")
abline(v = log(cv_lasso$lambda.min), col = "red", lty = 2)
abline(v = log(cv_lasso$lambda.1se), col = "blue", lty = 2)
legend("topright", legend = c("lambda.min", "lambda.1se"), 
       col = c("red", "blue"), lty = 2)

# Extract non-zero coefficients
lasso_coef <- coef(cv_lasso, s = "lambda.1se")
lasso_vars <- rownames(lasso_coef)[lasso_coef[,1] != 0][-1]  # Remove intercept

cat("\nLASSO selected", length(lasso_vars), "variables:\n")
print(lasso_vars)

# Create dataset with LASSO-selected variables
data_lasso_selected <- predictor_data[, lasso_vars, drop = FALSE]
```

## 4.4 Method 4: Random Forest Variable Importance

```{r rf_importance, cache=TRUE}
# Fit random forest
set.seed(123)
rf_model <- randomForest(
  x = predictor_data[train_idx, ],
  y = data$critical_temp_transformed[train_idx],
  importance = TRUE,
  ntree = 100  # Reduced for speed
)

# Extract variable importance
importance_df <- data.frame(
  Variable = rownames(importance(rf_model)),
  Importance = importance(rf_model)[, "%IncMSE"]
) %>%
  arrange(desc(Importance))

# Plot top 20 important variables
ggplot(head(importance_df, 20), 
       aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "darkgreen", alpha = 0.7) +
  coord_flip() +
  labs(title = "Top 20 Most Important Variables (Random Forest)",
       x = "Variable", y = "Importance (%IncMSE)") +
  theme_minimal()

# Select top N variables
top_n_vars <- 30
rf_selected_vars <- head(importance_df$Variable, top_n_vars)
data_rf_selected <- predictor_data[, rf_selected_vars, drop = FALSE]

cat("\nRandom Forest selected top", top_n_vars, "variables\n")
```

## 4.5 Feature Selection Summary

```{r selection_summary}
# Compare different selection methods
selection_summary <- data.frame(
  Method = c("Original", "Correlation-based", "LASSO", "Random Forest (Top 30)"),
  Number_of_Features = c(
    ncol(predictor_data),
    ncol(data_cor_selected),
    length(lasso_vars),
    top_n_vars
  )
)

kable(selection_summary, caption = "Feature Selection Methods Comparison") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

# 5. Model Building

## 5.1 Train-Test Split

```{r train_test_split}
set.seed(123)
train_index <- createDataPartition(data$critical_temp_transformed, 
                                   p = 0.7, list = FALSE)

# Prepare datasets for different selection methods
prepare_train_test <- function(predictors, target) {
  train_data <- data.frame(predictors[train_index, ], 
                          critical_temp_transformed = target[train_index])
  test_data <- data.frame(predictors[-train_index, ], 
                         critical_temp_transformed = target[-train_index])
  list(train = train_data, test = test_data)
}

# Full model data
full_split <- prepare_train_test(predictor_data, data$critical_temp_transformed)

# LASSO selected data
lasso_split <- prepare_train_test(data_lasso_selected, data$critical_temp_transformed)

# Random Forest selected data
rf_split <- prepare_train_test(data_rf_selected, data$critical_temp_transformed)

cat("Training set size:", nrow(full_split$train), "\n")
cat("Test set size:", nrow(full_split$test), "\n")
```

## 5.2 Full Linear Regression Model

```{r full_model}
# Fit full model
model_full <- lm(critical_temp_transformed ~ ., data = full_split$train)

# Model summary
summary(model_full)

# Extract key metrics
cat("\n=== Full Model Performance ===\n")
cat("R-squared:", round(summary(model_full)$r.squared, 4), "\n")
cat("Adjusted R-squared:", round(summary(model_full)$adj.r.squared, 4), "\n")
cat("F-statistic:", round(summary(model_full)$fstatistic[1], 2), "\n")
cat("P-value:", format.pval(pf(summary(model_full)$fstatistic[1],
                               summary(model_full)$fstatistic[2],
                               summary(model_full)$fstatistic[3],
                               lower.tail = FALSE), digits = 3), "\n")
```

## 5.3 Reduced Models

```{r reduced_models}
# LASSO-selected model
model_lasso <- lm(critical_temp_transformed ~ ., data = lasso_split$train)

# Random Forest-selected model
model_rf <- lm(critical_temp_transformed ~ ., data = rf_split$train)

# Compare models
model_comparison <- data.frame(
  Model = c("Full Model", "LASSO Selected", "RF Selected"),
  Num_Predictors = c(
    length(coef(model_full)) - 1,
    length(coef(model_lasso)) - 1,
    length(coef(model_rf)) - 1
  ),
  R_Squared = c(
    summary(model_full)$r.squared,
    summary(model_lasso)$r.squared,
    summary(model_rf)$r.squared
  ),
  Adj_R_Squared = c(
    summary(model_full)$adj.r.squared,
    summary(model_lasso)$adj.r.squared,
    summary(model_rf)$adj.r.squared
  )
)

kable(model_comparison, digits = 4, 
      caption = "Model Comparison on Training Set") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

# 6. Model Evaluation

## 6.1 Predictions and Performance Metrics

```{r model_evaluation}
# Function to calculate performance metrics
calc_metrics <- function(actual, predicted) {
  mse <- mean((actual - predicted)^2)
  mae <- mean(abs(actual - predicted))
  rmse <- sqrt(mse)
  r_squared <- 1 - sum((actual - predicted)^2) / sum((actual - mean(actual))^2)
  
  return(data.frame(
    MSE = mse,
    MAE = mae,
    RMSE = rmse,
    R_Squared = r_squared
  ))
}

# Make predictions on test set
pred_full <- predict(model_full, newdata = full_split$test)
pred_lasso <- predict(model_lasso, newdata = lasso_split$test)
pred_rf <- predict(model_rf, newdata = rf_split$test)

# Calculate metrics
metrics_full_train <- calc_metrics(full_split$train$critical_temp_transformed, 
                                   predict(model_full, newdata = full_split$train))
metrics_full_test <- calc_metrics(full_split$test$critical_temp_transformed, pred_full)

metrics_lasso_train <- calc_metrics(lasso_split$train$critical_temp_transformed,
                                    predict(model_lasso, newdata = lasso_split$train))
metrics_lasso_test <- calc_metrics(lasso_split$test$critical_temp_transformed, pred_lasso)

metrics_rf_train <- calc_metrics(rf_split$train$critical_temp_transformed,
                                 predict(model_rf, newdata = rf_split$train))
metrics_rf_test <- calc_metrics(rf_split$test$critical_temp_transformed, pred_rf)

# Combine results
results_comparison <- data.frame(
  Model = rep(c("Full Model", "LASSO Selected", "RF Selected"), each = 2),
  Dataset = rep(c("Train", "Test"), 3),
  rbind(metrics_full_train, metrics_full_test,
        metrics_lasso_train, metrics_lasso_test,
        metrics_rf_train, metrics_rf_test)
)

kable(results_comparison, digits = 4,
      caption = "Model Performance Comparison") %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  row_spec(seq(2, 6, 2), background = "#f0f0f0")
```

## 6.2 Visualize Predictions

```{r prediction_viz}
# Create prediction dataframes
pred_df_full <- data.frame(
  Actual = full_split$test$critical_temp_transformed,
  Predicted = pred_full,
  Model = "Full Model"
)

pred_df_lasso <- data.frame(
  Actual = lasso_split$test$critical_temp_transformed,
  Predicted = pred_lasso,
  Model = "LASSO Selected"
)

pred_df_rf <- data.frame(
  Actual = rf_split$test$critical_temp_transformed,
  Predicted = pred_rf,
  Model = "RF Selected"
)

pred_combined <- rbind(pred_df_full, pred_df_lasso, pred_df_rf)

# Plot actual vs predicted
ggplot(pred_combined, aes(x = Actual, y = Predicted)) +
  geom_point(alpha = 0.4, color = "steelblue") +
  geom_abline(intercept = 0, slope = 1, color = "red", 
              linetype = "dashed", size = 1) +
  facet_wrap(~ Model) +
  labs(title = "Actual vs Predicted Critical Temperature (Transformed)",
       subtitle = "Red line represents perfect prediction",
       x = "Actual Critical Temperature",
       y = "Predicted Critical Temperature") +
  theme_minimal()
```

## 6.3 Residual Analysis

```{r residual_plots}
# Using the best performing model (let's use LASSO for this example)
best_model <- model_lasso
best_test <- lasso_split$test
best_pred <- pred_lasso

residuals_test <- best_test$critical_temp_transformed - best_pred
fitted_test <- best_pred

# 1. Residuals vs Fitted
p1 <- ggplot(data.frame(Fitted = fitted_test, Residuals = residuals_test),
             aes(x = Fitted, y = Residuals)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  geom_smooth(se = FALSE, color = "blue") +
  labs(title = "Residuals vs Fitted Values",
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()

# 2. Q-Q Plot
p2 <- ggplot(data.frame(Residuals = residuals_test), 
             aes(sample = Residuals)) +
  stat_qq() +
  stat_qq_line(color = "red", size = 1) +
  labs(title = "Normal Q-Q Plot",
       x = "Theoretical Quantiles", y = "Sample Quantiles") +
  theme_minimal()

# 3. Scale-Location
p3 <- ggplot(data.frame(Fitted = fitted_test, 
                       StdResiduals = sqrt(abs(scale(residuals_test)))),
             aes(x = Fitted, y = StdResiduals)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = FALSE, color = "red") +
  labs(title = "Scale-Location Plot",
       x = "Fitted Values", y = "√|Standardized Residuals|") +
  theme_minimal()

# 4. Residual Histogram
p4 <- ggplot(data.frame(Residuals = residuals_test), 
             aes(x = Residuals)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, 
                 fill = "steelblue", alpha = 0.7) +
  geom_density(color = "red", size = 1) +
  labs(title = "Distribution of Residuals",
       x = "Residuals", y = "Density") +
  theme_minimal()

grid.arrange(p1, p2, p3, p4, ncol = 2)
```

# 7. Diagnostic Tests

```{r diagnostic_tests}
# Perform diagnostic tests on the best model
cat("=== DIAGNOSTIC TESTS ===\n\n")

# 1. Normality Test (Shapiro-Wilk on sample of residuals)
if(length(residuals_test) > 5000) {
  # Shapiro test limited to 5000 observations
  sample_idx <- sample(1:length(residuals_test), 5000)
  shapiro_result <- shapiro.test(residuals_test[sample_idx])
} else {
  shapiro_result <- shapiro.test(residuals_test)
}
cat("1. Shapiro-Wilk Normality Test\n")
cat("   W =", round(shapiro_result$statistic, 4), 
    "  p-value =", format.pval(shapiro_result$p.value, digits = 3), "\n")
cat("   Interpretation:", ifelse(shapiro_result$p.value > 0.05,
                                 "Residuals are approximately normal",
                                 "Residuals deviate from normality"), "\n\n")

# 2. Homoscedasticity Test (Breusch-Pagan)
library(lmtest)
bp_test <- bptest(best_model)
cat("2. Breusch-Pagan Test for Homoscedasticity\n")
cat("   BP =", round(bp_test$statistic, 4), 
    "  p-value =", format.pval(bp_test$p.value, digits = 3), "\n")
cat("   Interpretation:", ifelse(bp_test$p.value > 0.05,
                                 "Homoscedasticity assumption met",
                                 "Heteroscedasticity detected"), "\n\n")

# 3. Independence Test (Durbin-Watson)
dw_test <- dwtest(best_model)
cat("3. Durbin-Watson Test for Independence\n")
cat("   DW =", round(dw_test$statistic, 4), 
    "  p-value =", format.pval(dw_test$p.value, digits = 3), "\n")
cat("   Interpretation:", 
    ifelse(dw_test$statistic > 1.5 & dw_test$statistic < 2.5,
           "Residuals are approximately independent",
           "Autocorrelation may be present"), "\n\n")

# 4. Outliers (Cook's Distance)
cooks_d <- cooks.distance(best_model)
threshold <- 4 / nrow(lasso_split$train)
influential <- which(cooks_d > threshold)

cat("4. Cook's Distance for Outliers\n")
cat("   Threshold:", round(threshold, 6), "\n")
cat("   Number of influential points:", length(influential), 
    "(", round(100 * length(influential) / length(cooks_d), 2), "%)\n")

# Plot Cook's Distance
ggplot(data.frame(Index = 1:length(cooks_d), CooksD = cooks_d),
       aes(x = Index, y = CooksD)) +
  geom_bar(stat = "identity", fill = ifelse(cooks_d > threshold, "red", "steelblue")) +
  geom_hline(yintercept = threshold, color = "red", linetype = "dashed") +
  labs(title = "Cook's Distance for Outlier Detection",
       subtitle = paste("Red bars indicate influential points (n =", length(influential), ")"),
       x = "Observation Index", y = "Cook's Distance") +
  theme_minimal()
```

# 8. Interpretation and Insights

## 8.1 Most Important Predictors

```{r important_predictors}
# Extract coefficients from the best model
coef_df <- data.frame(
  Variable = names(coef(best_model))[-1],  # Exclude intercept
  Coefficient = coef(best_model)[-1],
  Abs_Coefficient = abs(coef(best_model)[-1])
) %>%
  arrange(desc(Abs_Coefficient))

cat("Top 15 Most Important Predictors (by coefficient magnitude):\n")
kable(head(coef_df, 15), digits = 4,
      caption = "Top Predictors in Selected Model") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Visualize
ggplot(head(coef_df, 20), 
       aes(x = reorder(Variable, Abs_Coefficient), y = Coefficient)) +
  geom_bar(stat = "identity", aes(fill = Coefficient > 0)) +
  coord_flip() +
  scale_fill_manual(values = c("coral", "steelblue"),
                    labels = c("Negative", "Positive")) +
  labs(title = "Top 20 Predictors by Coefficient Magnitude",
       x = "Variable", y = "Coefficient Value",
       fill = "Effect") +
  theme_minimal()
```

## 8.2 Model Limitations

Based on the analysis, the linear regression model has the following limitations:

1. **Multicollinearity**: High correlation among predictors (as seen in correlation matrix)
2. **Non-normality**: Even after transformation, some deviation from normality
3. **Prediction Bias**: Evidence of over/under-prediction for extreme values
4. **Outliers**: Presence of influential observations

## 8.3 Recommendations

1. **Consider Alternative Models**:
   - Regularized regression (Ridge, Elastic Net)
   - Tree-based methods (Random Forest, XGBoost, Gradient Boosting)
   - Neural networks for complex non-linear relationships

2. **Advanced Feature Engineering**:
   - Principal Component Analysis (PCA) for dimensionality reduction
   - Polynomial features for capturing non-linearities
   - Domain-specific feature creation

3. **Ensemble Approaches**:
   - Combine predictions from multiple models
   - Stack linear model with non-linear models

# 9. Conclusion

## 9.1 Summary

This analysis explored linear regression modeling for predicting superconductor critical temperatures using the UCI dataset. Key findings:

- **Dataset**: 21,263 superconductors with 81 features
- **Target Transformation**: Box-Cox transformation improved normality (λ ≈ `r round(lambda, 3)`)
- **Feature Selection**: Multiple methods identified 15-30 most important features
- **Model Performance**: 
  - Best model achieved R² ≈ `r round(results_comparison$R_Squared[results_comparison$Model == "RF Selected" & results_comparison$Dataset == "Test"], 3)` on test set
  - RMSE ≈ `r round(results_comparison$RMSE[results_comparison$Model == "RF Selected" & results_comparison$Dataset == "Test"], 2)` (transformed scale)

## 9.2 Key Takeaways

1. Linear regression provides interpretable baseline but has limitations
2. Feature selection significantly improves model parsimony without major performance loss
3. Advanced methods (ensemble, deep learning) may capture complex relationships better
4. Domain knowledge crucial for feature engineering and interpretation

## 9.3 Citation

**Remember to cite:**  
Hamidieh, Kam. "A data-driven statistical model for predicting the critical temperature of a superconductor." *Computational Materials Science* 154 (2018): 346–354. DOI: 10.1016/j.commatsci.2018.07.052

---

# Appendix: Session Information

```{r session_info}
sessionInfo()
```